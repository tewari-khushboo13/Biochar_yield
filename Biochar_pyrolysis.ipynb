{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tewari-khushboo13/Biochar_yield/blob/main/Biochar_pyrolysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RANDOM** **FOREST** **REGRESSION**"
      ],
      "metadata": {
        "id": "sISCIfaQjxEk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTAT4ExWdbOB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Pyrolysis_biochar.csv')\n",
        "X = dataset.iloc[:, 2:12].values\n",
        "y = dataset.iloc[:, 12].values\n"
      ],
      "metadata": {
        "id": "Rrb5cq_KeRsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
        "imputer.fit(X[:,2:12])\n",
        "X[:,2:12]=imputer.transform(X[:,2:12])"
      ],
      "metadata": {
        "id": "cduHqXeieZjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
      ],
      "metadata": {
        "id": "VsS4xky4ewbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "iseoqUUNgDud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regressor = RandomForestRegressor(n_estimators = 200, random_state = 0,min_samples_split= 2, min_samples_leaf= 1, max_features='auto', max_depth= None)\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "I0q3slmRVeoH",
        "outputId": "f804783f-4e0a-4e81-dc93-d2d7af66bdca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_features='auto', n_estimators=200, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_features=&#x27;auto&#x27;, n_estimators=200, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_features=&#x27;auto&#x27;, n_estimators=200, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr-lSHwDVeqA",
        "outputId": "d3d7818d-90c3-4f01-f836-a6d57d218ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[27.69555 29.08   ]\n",
            " [35.0552  36.68   ]\n",
            " [36.61955 39.15   ]\n",
            " [34.3768  33.52   ]\n",
            " [25.4947  22.3    ]\n",
            " [35.63375 32.59   ]\n",
            " [28.34695 29.38   ]\n",
            " [27.008   26.3    ]\n",
            " [79.10475 91.     ]\n",
            " [36.84355 36.69   ]\n",
            " [25.54115 25.32   ]\n",
            " [32.6306  32.08   ]\n",
            " [62.1584  49.8    ]\n",
            " [30.3362  36.12   ]\n",
            " [29.74855 29.1    ]\n",
            " [65.8608  79.19   ]\n",
            " [35.18625 35.86   ]\n",
            " [79.10475 89.17   ]\n",
            " [34.3752  32.65   ]\n",
            " [40.55915 43.22   ]\n",
            " [38.9459  42.73   ]\n",
            " [26.59675 24.5    ]\n",
            " [29.89225 30.53   ]\n",
            " [69.562   72.85   ]\n",
            " [82.036   80.13   ]\n",
            " [32.24915 31.92   ]\n",
            " [65.5687  56.34   ]\n",
            " [42.8195  40.5    ]\n",
            " [32.5534  31.89   ]\n",
            " [30.75275 32.13   ]\n",
            " [37.55775 42.61   ]\n",
            " [30.7061  29.32   ]\n",
            " [64.58435 72.     ]\n",
            " [28.4804  29.06   ]\n",
            " [69.4721  74.32   ]\n",
            " [61.90795 72.32   ]\n",
            " [34.1752  35.79   ]\n",
            " [34.60105 34.4    ]\n",
            " [32.7527  38.7    ]\n",
            " [25.10105 23.3    ]\n",
            " [40.46505 41.08   ]\n",
            " [35.00445 30.8    ]\n",
            " [32.1785  31.1    ]\n",
            " [33.88835 30.51   ]\n",
            " [26.2254  23.1    ]\n",
            " [43.22795 45.39   ]\n",
            " [41.69305 46.6    ]\n",
            " [27.76795 24.     ]\n",
            " [44.0961  50.92   ]\n",
            " [51.6139  56.71   ]\n",
            " [44.6725  35.1    ]\n",
            " [41.80995 49.11   ]\n",
            " [42.6337  42.82   ]\n",
            " [61.7174  55.65   ]\n",
            " [43.41335 53.68   ]\n",
            " [35.47715 36.01   ]\n",
            " [67.384   62.73   ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-nPBieSVetj",
        "outputId": "5f425922-26ef-4830-f3af-b087ea11bcdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9128933466698091"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "XCB3hy9qeOQy",
        "outputId": "34028c94-885a-447f-9626-049d142fc406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(n_estimators=10, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKuKiMitghfB",
        "outputId": "45db06e2-0cd5-4f7e-8bf5-ba6c8af3d417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[27.846 29.08 ]\n",
            " [34.479 36.68 ]\n",
            " [35.612 39.15 ]\n",
            " [34.628 33.52 ]\n",
            " [25.149 22.3  ]\n",
            " [35.52  32.59 ]\n",
            " [27.846 29.38 ]\n",
            " [26.849 26.3  ]\n",
            " [78.48  91.   ]\n",
            " [36.883 36.69 ]\n",
            " [27.011 25.32 ]\n",
            " [33.058 32.08 ]\n",
            " [57.204 49.8  ]\n",
            " [29.916 36.12 ]\n",
            " [29.443 29.1  ]\n",
            " [65.325 79.19 ]\n",
            " [35.321 35.86 ]\n",
            " [78.48  89.17 ]\n",
            " [33.742 32.65 ]\n",
            " [42.258 43.22 ]\n",
            " [41.812 42.73 ]\n",
            " [26.931 24.5  ]\n",
            " [30.888 30.53 ]\n",
            " [69.669 72.85 ]\n",
            " [81.718 80.13 ]\n",
            " [32.57  31.92 ]\n",
            " [65.587 56.34 ]\n",
            " [42.776 40.5  ]\n",
            " [31.179 31.89 ]\n",
            " [31.736 32.13 ]\n",
            " [38.988 42.61 ]\n",
            " [30.828 29.32 ]\n",
            " [64.922 72.   ]\n",
            " [27.656 29.06 ]\n",
            " [67.883 74.32 ]\n",
            " [58.776 72.32 ]\n",
            " [33.89  35.79 ]\n",
            " [35.124 34.4  ]\n",
            " [33.411 38.7  ]\n",
            " [26.512 23.3  ]\n",
            " [40.376 41.08 ]\n",
            " [38.582 30.8  ]\n",
            " [32.796 31.1  ]\n",
            " [35.557 30.51 ]\n",
            " [26.807 23.1  ]\n",
            " [42.692 45.39 ]\n",
            " [44.545 46.6  ]\n",
            " [25.696 24.   ]\n",
            " [44.62  50.92 ]\n",
            " [51.615 56.71 ]\n",
            " [41.659 35.1  ]\n",
            " [42.971 49.11 ]\n",
            " [41.605 42.82 ]\n",
            " [61.916 55.65 ]\n",
            " [43.004 53.68 ]\n",
            " [36.505 36.01 ]\n",
            " [67.407 62.73 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKR2bKWVh5Fo",
        "outputId": "117d17fc-70fd-4930-c11e-91a71c9e6f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9134177625609902"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NEURAL** **NETWORK**"
      ],
      "metadata": {
        "id": "4b87w3icjpv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "qayB0c8TjV-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "L90z0zTekgMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=10, activation='relu',input_dim=10,kernel_initializer='normal'))"
      ],
      "metadata": {
        "id": "9pDPRTlFknFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=10, activation='tanh',kernel_initializer='normal'))"
      ],
      "metadata": {
        "id": "7beKQAntksLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1, kernel_initializer='normal'))"
      ],
      "metadata": {
        "id": "Rx2BcnLyk0Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8LTbfpcEk-RX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train, y_train, batch_size = 1, epochs = 300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEi_3DvllFgU",
        "outputId": "52f3bdf6-f097-4bfc-af64-c54528e0850a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "169/169 [==============================] - 1s 2ms/step - loss: 1639.1343 - accuracy: 0.0000e+00\n",
            "Epoch 2/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1426.2986 - accuracy: 0.0000e+00\n",
            "Epoch 3/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1238.6700 - accuracy: 0.0000e+00\n",
            "Epoch 4/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1109.8348 - accuracy: 0.0000e+00\n",
            "Epoch 5/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 1004.0090 - accuracy: 0.0000e+00\n",
            "Epoch 6/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 911.6604 - accuracy: 0.0000e+00\n",
            "Epoch 7/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 829.7509 - accuracy: 0.0000e+00\n",
            "Epoch 8/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 756.2137 - accuracy: 0.0000e+00\n",
            "Epoch 9/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 690.1988 - accuracy: 0.0000e+00\n",
            "Epoch 10/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 630.5576 - accuracy: 0.0000e+00\n",
            "Epoch 11/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 576.9454 - accuracy: 0.0000e+00\n",
            "Epoch 12/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 529.0306 - accuracy: 0.0000e+00\n",
            "Epoch 13/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 485.8722 - accuracy: 0.0000e+00\n",
            "Epoch 14/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 447.2187 - accuracy: 0.0000e+00\n",
            "Epoch 15/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 412.9367 - accuracy: 0.0000e+00\n",
            "Epoch 16/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 382.6296 - accuracy: 0.0000e+00\n",
            "Epoch 17/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 355.7181 - accuracy: 0.0000e+00\n",
            "Epoch 18/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 332.0450 - accuracy: 0.0000e+00\n",
            "Epoch 19/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 311.1829 - accuracy: 0.0000e+00\n",
            "Epoch 20/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 293.0935 - accuracy: 0.0000e+00\n",
            "Epoch 21/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 277.4167 - accuracy: 0.0000e+00\n",
            "Epoch 22/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 263.9708 - accuracy: 0.0000e+00\n",
            "Epoch 23/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 252.3292 - accuracy: 0.0000e+00\n",
            "Epoch 24/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 242.6230 - accuracy: 0.0000e+00\n",
            "Epoch 25/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 234.0447 - accuracy: 0.0000e+00\n",
            "Epoch 26/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 222.2144 - accuracy: 0.0000e+00\n",
            "Epoch 27/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 210.9872 - accuracy: 0.0000e+00\n",
            "Epoch 28/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 202.2068 - accuracy: 0.0000e+00\n",
            "Epoch 29/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 194.3312 - accuracy: 0.0000e+00\n",
            "Epoch 30/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 187.5025 - accuracy: 0.0000e+00\n",
            "Epoch 31/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 181.3369 - accuracy: 0.0000e+00\n",
            "Epoch 32/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 175.2084 - accuracy: 0.0000e+00\n",
            "Epoch 33/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 169.8035 - accuracy: 0.0000e+00\n",
            "Epoch 34/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 164.6604 - accuracy: 0.0000e+00\n",
            "Epoch 35/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 158.1022 - accuracy: 0.0000e+00\n",
            "Epoch 36/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 152.7826 - accuracy: 0.0000e+00\n",
            "Epoch 37/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 148.3566 - accuracy: 0.0000e+00\n",
            "Epoch 38/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 144.3256 - accuracy: 0.0000e+00\n",
            "Epoch 39/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 140.7614 - accuracy: 0.0000e+00\n",
            "Epoch 40/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 137.2901 - accuracy: 0.0000e+00\n",
            "Epoch 41/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 133.8871 - accuracy: 0.0000e+00\n",
            "Epoch 42/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 131.2398 - accuracy: 0.0000e+00\n",
            "Epoch 43/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 128.2125 - accuracy: 0.0000e+00\n",
            "Epoch 44/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 125.5520 - accuracy: 0.0000e+00\n",
            "Epoch 45/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 122.5262 - accuracy: 0.0000e+00\n",
            "Epoch 46/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 119.9179 - accuracy: 0.0000e+00\n",
            "Epoch 47/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 116.9650 - accuracy: 0.0000e+00\n",
            "Epoch 48/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 113.7471 - accuracy: 0.0000e+00\n",
            "Epoch 49/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 111.2243 - accuracy: 0.0000e+00\n",
            "Epoch 50/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 108.4354 - accuracy: 0.0000e+00\n",
            "Epoch 51/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 105.6022 - accuracy: 0.0000e+00\n",
            "Epoch 52/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 103.0874 - accuracy: 0.0000e+00\n",
            "Epoch 53/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 100.7980 - accuracy: 0.0000e+00\n",
            "Epoch 54/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 98.8026 - accuracy: 0.0000e+00\n",
            "Epoch 55/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 96.7403 - accuracy: 0.0000e+00\n",
            "Epoch 56/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 94.6903 - accuracy: 0.0000e+00\n",
            "Epoch 57/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 92.6898 - accuracy: 0.0000e+00\n",
            "Epoch 58/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 90.8693 - accuracy: 0.0000e+00\n",
            "Epoch 59/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 88.5284 - accuracy: 0.0000e+00\n",
            "Epoch 60/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 86.1737 - accuracy: 0.0000e+00\n",
            "Epoch 61/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 83.8409 - accuracy: 0.0000e+00\n",
            "Epoch 62/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 81.3794 - accuracy: 0.0000e+00\n",
            "Epoch 63/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 78.6983 - accuracy: 0.0000e+00\n",
            "Epoch 64/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 76.0731 - accuracy: 0.0000e+00\n",
            "Epoch 65/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 74.0283 - accuracy: 0.0000e+00\n",
            "Epoch 66/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 71.5769 - accuracy: 0.0000e+00\n",
            "Epoch 67/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 69.6102 - accuracy: 0.0000e+00\n",
            "Epoch 68/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 67.9186 - accuracy: 0.0000e+00\n",
            "Epoch 69/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 66.0344 - accuracy: 0.0000e+00\n",
            "Epoch 70/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 64.1822 - accuracy: 0.0000e+00\n",
            "Epoch 71/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 62.2358 - accuracy: 0.0000e+00\n",
            "Epoch 72/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 60.7822 - accuracy: 0.0000e+00\n",
            "Epoch 73/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 59.6104 - accuracy: 0.0000e+00\n",
            "Epoch 74/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 57.7573 - accuracy: 0.0000e+00\n",
            "Epoch 75/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 56.6954 - accuracy: 0.0000e+00\n",
            "Epoch 76/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 55.7431 - accuracy: 0.0000e+00\n",
            "Epoch 77/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 54.4466 - accuracy: 0.0000e+00\n",
            "Epoch 78/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 53.2846 - accuracy: 0.0000e+00\n",
            "Epoch 79/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 52.2159 - accuracy: 0.0000e+00\n",
            "Epoch 80/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 51.2554 - accuracy: 0.0000e+00\n",
            "Epoch 81/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 49.9793 - accuracy: 0.0000e+00\n",
            "Epoch 82/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 49.3459 - accuracy: 0.0000e+00\n",
            "Epoch 83/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 48.3978 - accuracy: 0.0000e+00\n",
            "Epoch 84/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 47.3310 - accuracy: 0.0000e+00\n",
            "Epoch 85/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 46.5695 - accuracy: 0.0000e+00\n",
            "Epoch 86/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 45.9039 - accuracy: 0.0000e+00\n",
            "Epoch 87/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 44.7051 - accuracy: 0.0000e+00\n",
            "Epoch 88/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 44.8617 - accuracy: 0.0000e+00\n",
            "Epoch 89/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 43.3673 - accuracy: 0.0000e+00\n",
            "Epoch 90/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 42.5596 - accuracy: 0.0000e+00\n",
            "Epoch 91/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 41.2461 - accuracy: 0.0000e+00\n",
            "Epoch 92/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 40.6453 - accuracy: 0.0000e+00\n",
            "Epoch 93/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 38.4577 - accuracy: 0.0000e+00\n",
            "Epoch 94/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 36.2551 - accuracy: 0.0000e+00\n",
            "Epoch 95/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 35.7194 - accuracy: 0.0000e+00\n",
            "Epoch 96/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 34.3064 - accuracy: 0.0000e+00\n",
            "Epoch 97/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 32.6936 - accuracy: 0.0000e+00\n",
            "Epoch 98/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 31.3251 - accuracy: 0.0000e+00\n",
            "Epoch 99/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 30.8858 - accuracy: 0.0000e+00\n",
            "Epoch 100/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 29.4956 - accuracy: 0.0000e+00\n",
            "Epoch 101/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 28.7843 - accuracy: 0.0000e+00\n",
            "Epoch 102/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 28.4796 - accuracy: 0.0000e+00\n",
            "Epoch 103/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 27.3787 - accuracy: 0.0000e+00\n",
            "Epoch 104/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 26.4263 - accuracy: 0.0000e+00\n",
            "Epoch 105/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 26.1520 - accuracy: 0.0000e+00\n",
            "Epoch 106/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 25.1913 - accuracy: 0.0000e+00\n",
            "Epoch 107/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 24.7484 - accuracy: 0.0000e+00\n",
            "Epoch 108/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 24.1877 - accuracy: 0.0000e+00\n",
            "Epoch 109/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 24.0766 - accuracy: 0.0000e+00\n",
            "Epoch 110/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 23.2600 - accuracy: 0.0000e+00\n",
            "Epoch 111/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 23.1943 - accuracy: 0.0000e+00\n",
            "Epoch 112/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 22.8441 - accuracy: 0.0000e+00\n",
            "Epoch 113/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 22.3473 - accuracy: 0.0000e+00\n",
            "Epoch 114/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 21.5385 - accuracy: 0.0000e+00\n",
            "Epoch 115/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 21.0238 - accuracy: 0.0000e+00\n",
            "Epoch 116/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 20.9807 - accuracy: 0.0000e+00\n",
            "Epoch 117/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 20.6654 - accuracy: 0.0000e+00\n",
            "Epoch 118/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 20.3160 - accuracy: 0.0000e+00\n",
            "Epoch 119/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 19.7454 - accuracy: 0.0000e+00\n",
            "Epoch 120/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 19.4923 - accuracy: 0.0000e+00\n",
            "Epoch 121/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 19.3703 - accuracy: 0.0000e+00\n",
            "Epoch 122/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 18.9653 - accuracy: 0.0000e+00\n",
            "Epoch 123/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 18.6422 - accuracy: 0.0000e+00\n",
            "Epoch 124/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 18.1753 - accuracy: 0.0000e+00\n",
            "Epoch 125/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 18.0725 - accuracy: 0.0000e+00\n",
            "Epoch 126/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 17.6118 - accuracy: 0.0000e+00\n",
            "Epoch 127/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 17.7138 - accuracy: 0.0000e+00\n",
            "Epoch 128/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 17.0494 - accuracy: 0.0000e+00\n",
            "Epoch 129/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 17.0172 - accuracy: 0.0000e+00\n",
            "Epoch 130/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 16.9904 - accuracy: 0.0000e+00\n",
            "Epoch 131/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 16.7697 - accuracy: 0.0000e+00\n",
            "Epoch 132/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 16.5838 - accuracy: 0.0000e+00\n",
            "Epoch 133/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 15.9559 - accuracy: 0.0000e+00\n",
            "Epoch 134/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 15.5803 - accuracy: 0.0000e+00\n",
            "Epoch 135/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 15.6044 - accuracy: 0.0000e+00\n",
            "Epoch 136/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 15.5426 - accuracy: 0.0000e+00\n",
            "Epoch 137/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 15.1481 - accuracy: 0.0000e+00\n",
            "Epoch 138/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 15.1056 - accuracy: 0.0000e+00\n",
            "Epoch 139/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 14.8810 - accuracy: 0.0000e+00\n",
            "Epoch 140/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 14.7861 - accuracy: 0.0000e+00\n",
            "Epoch 141/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 14.6818 - accuracy: 0.0000e+00\n",
            "Epoch 142/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 14.3514 - accuracy: 0.0000e+00\n",
            "Epoch 143/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 14.0432 - accuracy: 0.0000e+00\n",
            "Epoch 144/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 14.0193 - accuracy: 0.0000e+00\n",
            "Epoch 145/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 13.9904 - accuracy: 0.0000e+00\n",
            "Epoch 146/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 13.6497 - accuracy: 0.0000e+00\n",
            "Epoch 147/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 13.1316 - accuracy: 0.0000e+00\n",
            "Epoch 148/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 13.5884 - accuracy: 0.0000e+00\n",
            "Epoch 149/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 13.5880 - accuracy: 0.0000e+00\n",
            "Epoch 150/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 13.0040 - accuracy: 0.0000e+00\n",
            "Epoch 151/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 13.0406 - accuracy: 0.0000e+00\n",
            "Epoch 152/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 13.2223 - accuracy: 0.0000e+00\n",
            "Epoch 153/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 12.5068 - accuracy: 0.0000e+00\n",
            "Epoch 154/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 12.5715 - accuracy: 0.0000e+00\n",
            "Epoch 155/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 12.3339 - accuracy: 0.0000e+00\n",
            "Epoch 156/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 12.1306 - accuracy: 0.0000e+00\n",
            "Epoch 157/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 11.8787 - accuracy: 0.0000e+00\n",
            "Epoch 158/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 11.7423 - accuracy: 0.0000e+00\n",
            "Epoch 159/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 11.8456 - accuracy: 0.0000e+00\n",
            "Epoch 160/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 11.6406 - accuracy: 0.0000e+00\n",
            "Epoch 161/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 11.2837 - accuracy: 0.0000e+00\n",
            "Epoch 162/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 11.5024 - accuracy: 0.0000e+00\n",
            "Epoch 163/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 11.0486 - accuracy: 0.0000e+00\n",
            "Epoch 164/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 11.1402 - accuracy: 0.0000e+00\n",
            "Epoch 165/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 10.6389 - accuracy: 0.0000e+00\n",
            "Epoch 166/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 10.5020 - accuracy: 0.0000e+00\n",
            "Epoch 167/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 10.6691 - accuracy: 0.0000e+00\n",
            "Epoch 168/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 10.1895 - accuracy: 0.0000e+00\n",
            "Epoch 169/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 10.4778 - accuracy: 0.0000e+00\n",
            "Epoch 170/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 10.0576 - accuracy: 0.0000e+00\n",
            "Epoch 171/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 9.8518 - accuracy: 0.0000e+00\n",
            "Epoch 172/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 9.8605 - accuracy: 0.0000e+00\n",
            "Epoch 173/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 10.0494 - accuracy: 0.0000e+00\n",
            "Epoch 174/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 9.4435 - accuracy: 0.0000e+00\n",
            "Epoch 175/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 9.6644 - accuracy: 0.0000e+00\n",
            "Epoch 176/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 9.5800 - accuracy: 0.0000e+00\n",
            "Epoch 177/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 9.4269 - accuracy: 0.0000e+00\n",
            "Epoch 178/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 9.7599 - accuracy: 0.0000e+00\n",
            "Epoch 179/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 9.2101 - accuracy: 0.0000e+00\n",
            "Epoch 180/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 9.0168 - accuracy: 0.0000e+00\n",
            "Epoch 181/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.9985 - accuracy: 0.0000e+00\n",
            "Epoch 182/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.7785 - accuracy: 0.0000e+00\n",
            "Epoch 183/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 9.2883 - accuracy: 0.0000e+00\n",
            "Epoch 184/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 9.0026 - accuracy: 0.0000e+00\n",
            "Epoch 185/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.7927 - accuracy: 0.0000e+00\n",
            "Epoch 186/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.4207 - accuracy: 0.0000e+00\n",
            "Epoch 187/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 8.6731 - accuracy: 0.0000e+00\n",
            "Epoch 188/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.4881 - accuracy: 0.0000e+00\n",
            "Epoch 189/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.6202 - accuracy: 0.0000e+00\n",
            "Epoch 190/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.4066 - accuracy: 0.0000e+00\n",
            "Epoch 191/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.2433 - accuracy: 0.0000e+00\n",
            "Epoch 192/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.0966 - accuracy: 0.0000e+00\n",
            "Epoch 193/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.4797 - accuracy: 0.0000e+00\n",
            "Epoch 194/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.9121 - accuracy: 0.0000e+00\n",
            "Epoch 195/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.1889 - accuracy: 0.0000e+00\n",
            "Epoch 196/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.9947 - accuracy: 0.0000e+00\n",
            "Epoch 197/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.3211 - accuracy: 0.0000e+00\n",
            "Epoch 198/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.6729 - accuracy: 0.0000e+00\n",
            "Epoch 199/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.1607 - accuracy: 0.0000e+00\n",
            "Epoch 200/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.0038 - accuracy: 0.0000e+00\n",
            "Epoch 201/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.6165 - accuracy: 0.0000e+00\n",
            "Epoch 202/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 8.1136 - accuracy: 0.0000e+00\n",
            "Epoch 203/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 7.6371 - accuracy: 0.0000e+00\n",
            "Epoch 204/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.2380 - accuracy: 0.0000e+00\n",
            "Epoch 205/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.9780 - accuracy: 0.0000e+00\n",
            "Epoch 206/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.6035 - accuracy: 0.0000e+00\n",
            "Epoch 207/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.8216 - accuracy: 0.0000e+00\n",
            "Epoch 208/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.6249 - accuracy: 0.0000e+00\n",
            "Epoch 209/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.4997 - accuracy: 0.0000e+00\n",
            "Epoch 210/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.4115 - accuracy: 0.0000e+00\n",
            "Epoch 211/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.8339 - accuracy: 0.0000e+00\n",
            "Epoch 212/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.3794 - accuracy: 0.0000e+00\n",
            "Epoch 213/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.6587 - accuracy: 0.0000e+00\n",
            "Epoch 214/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.5961 - accuracy: 0.0000e+00\n",
            "Epoch 215/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.3865 - accuracy: 0.0000e+00\n",
            "Epoch 216/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.0177 - accuracy: 0.0000e+00\n",
            "Epoch 217/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.2753 - accuracy: 0.0000e+00\n",
            "Epoch 218/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 7.1195 - accuracy: 0.0000e+00\n",
            "Epoch 219/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.7783 - accuracy: 0.0000e+00\n",
            "Epoch 220/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.7668 - accuracy: 0.0000e+00\n",
            "Epoch 221/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.8815 - accuracy: 0.0000e+00\n",
            "Epoch 222/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.8363 - accuracy: 0.0000e+00\n",
            "Epoch 223/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.6106 - accuracy: 0.0000e+00\n",
            "Epoch 224/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.8356 - accuracy: 0.0000e+00\n",
            "Epoch 225/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.7982 - accuracy: 0.0000e+00\n",
            "Epoch 226/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.4246 - accuracy: 0.0000e+00\n",
            "Epoch 227/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.5817 - accuracy: 0.0000e+00\n",
            "Epoch 228/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.6588 - accuracy: 0.0000e+00\n",
            "Epoch 229/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.1551 - accuracy: 0.0000e+00\n",
            "Epoch 230/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.2730 - accuracy: 0.0000e+00\n",
            "Epoch 231/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.3579 - accuracy: 0.0000e+00\n",
            "Epoch 232/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.9904 - accuracy: 0.0000e+00\n",
            "Epoch 233/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.2887 - accuracy: 0.0000e+00\n",
            "Epoch 234/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.9833 - accuracy: 0.0000e+00\n",
            "Epoch 235/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 6.0360 - accuracy: 0.0000e+00\n",
            "Epoch 236/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.9860 - accuracy: 0.0000e+00\n",
            "Epoch 237/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.8422 - accuracy: 0.0000e+00\n",
            "Epoch 238/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.7373 - accuracy: 0.0000e+00\n",
            "Epoch 239/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.6253 - accuracy: 0.0000e+00\n",
            "Epoch 240/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.9321 - accuracy: 0.0000e+00\n",
            "Epoch 241/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.6031 - accuracy: 0.0000e+00\n",
            "Epoch 242/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.1969 - accuracy: 0.0000e+00\n",
            "Epoch 243/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.3579 - accuracy: 0.0000e+00\n",
            "Epoch 244/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.5530 - accuracy: 0.0000e+00\n",
            "Epoch 245/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.2916 - accuracy: 0.0000e+00\n",
            "Epoch 246/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.8733 - accuracy: 0.0000e+00\n",
            "Epoch 247/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.2605 - accuracy: 0.0000e+00\n",
            "Epoch 248/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.9629 - accuracy: 0.0000e+00\n",
            "Epoch 249/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.0814 - accuracy: 0.0000e+00\n",
            "Epoch 250/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.9991 - accuracy: 0.0000e+00\n",
            "Epoch 251/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 5.0612 - accuracy: 0.0000e+00\n",
            "Epoch 252/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.8627 - accuracy: 0.0000e+00\n",
            "Epoch 253/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.8998 - accuracy: 0.0000e+00\n",
            "Epoch 254/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.3958 - accuracy: 0.0000e+00\n",
            "Epoch 255/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.7842 - accuracy: 0.0000e+00\n",
            "Epoch 256/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.6291 - accuracy: 0.0000e+00\n",
            "Epoch 257/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.4208 - accuracy: 0.0000e+00\n",
            "Epoch 258/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.5131 - accuracy: 0.0000e+00\n",
            "Epoch 259/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.8982 - accuracy: 0.0000e+00\n",
            "Epoch 260/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.5856 - accuracy: 0.0000e+00\n",
            "Epoch 261/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.7039 - accuracy: 0.0000e+00\n",
            "Epoch 262/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.5305 - accuracy: 0.0000e+00\n",
            "Epoch 263/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.5918 - accuracy: 0.0000e+00\n",
            "Epoch 264/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 4.2677 - accuracy: 0.0000e+00\n",
            "Epoch 265/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.2012 - accuracy: 0.0000e+00\n",
            "Epoch 266/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.3770 - accuracy: 0.0000e+00\n",
            "Epoch 267/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.4718 - accuracy: 0.0000e+00\n",
            "Epoch 268/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.3277 - accuracy: 0.0000e+00\n",
            "Epoch 269/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.3306 - accuracy: 0.0000e+00\n",
            "Epoch 270/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.4326 - accuracy: 0.0000e+00\n",
            "Epoch 271/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.3554 - accuracy: 0.0000e+00\n",
            "Epoch 272/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.1484 - accuracy: 0.0000e+00\n",
            "Epoch 273/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.9829 - accuracy: 0.0000e+00\n",
            "Epoch 274/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.3487 - accuracy: 0.0000e+00\n",
            "Epoch 275/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.8688 - accuracy: 0.0000e+00\n",
            "Epoch 276/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.8649 - accuracy: 0.0000e+00\n",
            "Epoch 277/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.8706 - accuracy: 0.0000e+00\n",
            "Epoch 278/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.9685 - accuracy: 0.0000e+00\n",
            "Epoch 279/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.1045 - accuracy: 0.0000e+00\n",
            "Epoch 280/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.9107 - accuracy: 0.0000e+00\n",
            "Epoch 281/300\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 3.7696 - accuracy: 0.0000e+00\n",
            "Epoch 282/300\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 3.6673 - accuracy: 0.0000e+00\n",
            "Epoch 283/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.8200 - accuracy: 0.0000e+00\n",
            "Epoch 284/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.6318 - accuracy: 0.0000e+00\n",
            "Epoch 285/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.0993 - accuracy: 0.0000e+00\n",
            "Epoch 286/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.1295 - accuracy: 0.0000e+00\n",
            "Epoch 287/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.8709 - accuracy: 0.0000e+00\n",
            "Epoch 288/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.4030 - accuracy: 0.0000e+00\n",
            "Epoch 289/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.5394 - accuracy: 0.0000e+00\n",
            "Epoch 290/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 4.0515 - accuracy: 0.0000e+00\n",
            "Epoch 291/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.3604 - accuracy: 0.0000e+00\n",
            "Epoch 292/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.6639 - accuracy: 0.0000e+00\n",
            "Epoch 293/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.4233 - accuracy: 0.0000e+00\n",
            "Epoch 294/300\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 3.6014 - accuracy: 0.0000e+00\n",
            "Epoch 295/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.7670 - accuracy: 0.0000e+00\n",
            "Epoch 296/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.5627 - accuracy: 0.0000e+00\n",
            "Epoch 297/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.9439 - accuracy: 0.0000e+00\n",
            "Epoch 298/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.4759 - accuracy: 0.0000e+00\n",
            "Epoch 299/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.3034 - accuracy: 0.0000e+00\n",
            "Epoch 300/300\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 3.5478 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d924c38ad10>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOJBqgMeq6-_",
        "outputId": "032e0e7a-6587-4f88-b2ee-ec1ba9020925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step\n",
            "[[29.28092766 29.08      ]\n",
            " [36.44048691 36.68      ]\n",
            " [38.31069565 39.15      ]\n",
            " [35.30080414 33.52      ]\n",
            " [24.29964828 22.3       ]\n",
            " [28.22370529 32.59      ]\n",
            " [30.61302948 29.38      ]\n",
            " [26.05984306 26.3       ]\n",
            " [81.76432037 91.        ]\n",
            " [36.73873901 36.69      ]\n",
            " [25.00191116 25.32      ]\n",
            " [35.43663025 32.08      ]\n",
            " [61.97428513 49.8       ]\n",
            " [41.07035828 36.12      ]\n",
            " [28.88116074 29.1       ]\n",
            " [76.71110535 79.19      ]\n",
            " [37.7722702  35.86      ]\n",
            " [79.80693817 89.17      ]\n",
            " [32.18486404 32.65      ]\n",
            " [44.20731735 43.22      ]\n",
            " [43.55697632 42.73      ]\n",
            " [30.26502991 24.5       ]\n",
            " [33.73719788 30.53      ]\n",
            " [69.55995178 72.85      ]\n",
            " [75.91654205 80.13      ]\n",
            " [34.5812149  31.92      ]\n",
            " [66.80932617 56.34      ]\n",
            " [51.86859894 40.5       ]\n",
            " [32.30243301 31.89      ]\n",
            " [34.58221436 32.13      ]\n",
            " [44.81605911 42.61      ]\n",
            " [29.42026138 29.32      ]\n",
            " [72.51308441 72.        ]\n",
            " [30.763937   29.06      ]\n",
            " [73.61139679 74.32      ]\n",
            " [68.80945587 72.32      ]\n",
            " [33.21979904 35.79      ]\n",
            " [34.41939163 34.4       ]\n",
            " [48.47986221 38.7       ]\n",
            " [26.23066902 23.3       ]\n",
            " [39.13121033 41.08      ]\n",
            " [27.66599655 30.8       ]\n",
            " [32.63262177 31.1       ]\n",
            " [31.74669456 30.51      ]\n",
            " [28.10337639 23.1       ]\n",
            " [45.5839653  45.39      ]\n",
            " [47.03642654 46.6       ]\n",
            " [24.41984749 24.        ]\n",
            " [47.33311844 50.92      ]\n",
            " [58.29748154 56.71      ]\n",
            " [36.98308182 35.1       ]\n",
            " [48.98235703 49.11      ]\n",
            " [42.20349121 42.82      ]\n",
            " [60.24549484 55.65      ]\n",
            " [45.35620499 53.68      ]\n",
            " [36.5885849  36.01      ]\n",
            " [71.50093842 62.73      ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdYeYN4wGNVE",
        "outputId": "95101f36-8a56-4ff1-fcc8-fedeb690e3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9370191668819492"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}